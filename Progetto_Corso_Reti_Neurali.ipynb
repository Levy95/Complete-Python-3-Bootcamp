{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZ1W8QuZN7KTSfhQKIZy+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Levy95/Complete-Python-3-Bootcamp/blob/master/Progetto_Corso_Reti_Neurali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gptu6CkmSbgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device: serve per computare calcoli matriciali pi√π velocemente\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Gv-BPyfjSwTu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: MNIST.\n",
        "train_dataset_mnist = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train = True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "test_dataset_mnist = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train = False,\n",
        "                                          transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "rAprA0loUXsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: FashionMNIST\n",
        "train_dataset_fashionmnist = torchvision.datasets.FashionMNIST(root = './data',\n",
        "                                                               train = True,\n",
        "                                                               transform = transforms.ToTensor(),\n",
        "                                                               download = True)\n",
        "test_dataset_fashionmnist = torchvision.datasets.FashionMNIST(root='./data',\n",
        "                                                              train = True,\n",
        "                                                              transform = transforms.ToTensor())                          "
      ],
      "metadata": {
        "id": "aCEiaAx81m1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: CIFAR10\n",
        "train_dataset_cifar10 = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                                      train = True,\n",
        "                                                      transform = transforms.ToTensor(),\n",
        "                                                      download = True)\n",
        "test_dataset_cifar10 = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                                    train = False,\n",
        "                                                    transform = transforms.ToTensor())                                                                                                   "
      ],
      "metadata": {
        "id": "xDbPYH68FgcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rete Neurale Feed-Forward completamente connessa con un solo hidden-layer\n",
        "class ReteNeurale1(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, num_classi, act_func=1):\n",
        "   super(ReteNeurale1, self).__init__()\n",
        "   self.input_size = input_size\n",
        "   self.l1 = nn.Linear(input_size, hidden_size)\n",
        "   self.l2 = nn.Linear(hidden_size, num_classi)\n",
        "   if act_func == 1:\n",
        "    self.actfunc = nn.ReLU()\n",
        "   elif act_func == 2:\n",
        "    self.actfunc = nn.LeakyReLU()\n",
        "   elif act_func == 3:\n",
        "     self.actfunc = nn.Sigmoid() \n",
        "   \n",
        "\n",
        "  def forward(self, x):\n",
        "     out = self.l1(x)\n",
        "     out = self.actfunc(out)\n",
        "     out = self.l2(out)\n",
        "     return out"
      ],
      "metadata": {
        "id": "WYX4oSH8WStc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rete Neurale Feed-Forward completamente connessa con due hidden layers\n",
        "class ReteNeurale2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size1, hidden_size2, num_classi, act_func=1):\n",
        "    super(ReteNeurale2, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size1)\n",
        "    self.l2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    self.l3 = nn.Linear(hidden_size2, num_classi)\n",
        "    if act_func == 1:\n",
        "      self.actfunc = nn.ReLU()\n",
        "    elif act_func == 2:\n",
        "      self.actfunc = nn.LeakyReLU()\n",
        "    elif act_func == 3:\n",
        "      self.actfunc = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.actfunc(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.actfunc(out)\n",
        "    out = self.l3(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "qRWB-Dk92npY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione che implementa il training di una rete neurale che compie classificazione di immagini.\n",
        "\n",
        "def train_function(rete, load_tr_ds, opt, loss_fun, img_size, num_ep):\n",
        "  # Inputs.\n",
        "  # rete: istanza di una classe di rete neurale\n",
        "  # load_tr_ds: training (loader) set del dataset prescelto\n",
        "  # opt: algoritmo di learning\n",
        "  # img_size: dimensione delle immagini\n",
        "  # num_ep: numero di epoche di training\n",
        "  # Output: loss\n",
        "  n_tot_steps = len(load_tr_ds) # step = len(load_tr_ds)/batch_size\n",
        "  for epoch in range(num_ep):\n",
        "    for i, (immagini, etichette) in enumerate(load_tr_ds):\n",
        "      # si coverte il formato delle batch di dati\n",
        "      immagini = images.reshape(-1, img_size).to(device)\n",
        "      etichette = etichette.to(device)\n",
        "\n",
        "      # Forward step: si passano i dati attraverso i layer\n",
        "      outputs = rete(images)\n",
        "      # Si calcola la loss\n",
        "      loss = loss_fun(outputs, labels)\n",
        "      \n",
        "      # Training step: si calcola il gradiente della loss e si compie un passo \n",
        "      # dell'algoritnmo di training\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "       \n",
        "      # si stampano i valori della loss \n",
        "      if (i+1)%100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_ep}], Step [{i+1}/{n_tot_steps}], Loss: {loss.item():.4f}')\n",
        "    \n",
        "  print(f'Valore della loss dopo {num_ep} epoche: {loss}')  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "Y-4yywP8VdwD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione che testa una rete neurale neurale allenata per fare classificazione di immagini\n",
        "\n",
        "def test_function(rete, load_ts_ds, img_size):\n",
        "  # Input:\n",
        "  # rete: istanza di una classe di rete neurale\n",
        "  # lead_ts_ds: test (loader) set del dataset prescelto\n",
        "  # img_size: dimensione delle immagini\n",
        "  with torch.no_grad():\n",
        "    num_corrette = 0\n",
        "    num_campioni = 0\n",
        "    for immagini, etichette in load_ts_ds:\n",
        "      immagini = immagini.reshape(-1, img_size).to(device)\n",
        "      etichette = etichette.to(device)\n",
        "      output = rete(immagini)\n",
        "\n",
        "      # max ha come output una tupla del tipo (valore, indice)\n",
        "      _, pred = torch.max(output.data, 1)\n",
        "      num_campioni += etichette.size(0)\n",
        "      num_corrette += (pred == etichette).sum().item()\n",
        "\n",
        "    # accuratezza della rete: percentuali di immagini etichettate correttamente sul campione di dati\n",
        "    acc = 100 * num_corrette/num_campioni\n",
        "    print(f'Accuracy della rete su 10000 immagini test: {acc} %')\n",
        "    return acc"
      ],
      "metadata": {
        "id": "_lcRN0us-LYj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader_mnist = torch.utils.data.DataLoader(dataset=train_dataset_mnist,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle = True)\n",
        "test_loader_mnist = torch.utils.data.DataLoader(dataset= test_dataset_mnist,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "UqjYoRMQjeBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_fashionmnist = torch.utils.data.DataLoader(dataset = train_dataset_fashionmnist,\n",
        "                                                        batch_size = batch_size,\n",
        "                                                        shuffle=True)\n",
        "test_loader_fashionmnist = torch.utils.data.DataLoader(dataset = test_dataset_fashionmnist,\n",
        "                                                       batch_size = batch_size,\n",
        "                                                       shuffle = False)"
      ],
      "metadata": {
        "id": "VDSDCmRHjeKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_cifar10 = torch.utils.data.DataLoader(dataset = train_dataset_cifar10,\n",
        "                                                   batch_size = batch_size,\n",
        "                                                   shuffle = True)\n",
        "test_loader_cifar10 = torch.utils.data.DataLoader(dataset = test_dataset_cifar10,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = False)"
      ],
      "metadata": {
        "id": "nbvxrfWwjeUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}